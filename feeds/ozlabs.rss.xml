<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Store Half Byte-Reverse Indexed - OzLabs</title><link>https://sthbrx.github.io/</link><description>A Power Technical Blog</description><atom:link href="https://sthbrx.github.io/feeds/ozlabs.rss.xml" rel="self"></atom:link><lastBuildDate>Fri, 27 Jul 2018 00:00:00 +1000</lastBuildDate><item><title>Improving Phoronix Benchmarks Date: 2018-07-27 22:22 Authors: Rashmica</title><link>https://sthbrx.github.io/blog/2018/07/27/improving-phoronix-benchmarks-date-2018-07-27-2222-authors-rashmica/</link><description>&lt;p&gt;Gupta, Daniel Black, Anton Blanchard, Nick Piggin Category: Performance Tags:
performance, phoronix, benchmarks&lt;/p&gt;
&lt;h3&gt;Intro&lt;/h3&gt;
&lt;p&gt;Recently Phoronix ran a range of
&lt;a href="https://www.phoronix.com/scan.php?page=article&amp;amp;item=power9-talos-2&amp;amp;num=1"&gt;benchmarks&lt;/a&gt;
comparing the performance of our POWER9 processor against the Intel Xeon and AMD
EPYC processors. &lt;/p&gt;
&lt;p&gt;We did well in the Stockfish, LLVM Compilation, Zstd compression, and the
Tinymembench benchmarks. Some of my colleagues did a bit of investigating into
the benchmarks where we didn't perform quite so well.&lt;/p&gt;
&lt;p&gt;Some of the benchmarks where we don't perform as well as Intel are where the
benchmark has inline assembly for x86 but uses generic C compiler generated
assembly for POWER9. We also found a few things that should result in better
performance for all architectures.&lt;/p&gt;
&lt;h3&gt;LBM / Parboil The [Parboil&lt;/h3&gt;
&lt;p&gt;benchmarks](http://impact.crhc.illinois.edu/parboil/parboil.aspx) are a
collection of programs from various scientific and commercial fields that are
useful for examining the performance and development of different architectures
and tools.  Phoronix uses the lbm
&lt;a href="https://www.spec.org/cpu2006/Docs/470.lbm.html"&gt;benchmark&lt;/a&gt;: a fluid dynamics
simulation using the Lattice-Boltzmann Method.&lt;/p&gt;
&lt;p&gt;There were a couple of issues with this benchmark:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The benchmark is compiled without any optimisation. Adding -O3 improves the
   result 3.2x. Adding optimisation will improve x86_64, but we expect it to
improve POWER9 results a lot more.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Each time step has to complete before the next one can start.  Unfortunately
   the resolution is quite small, which means there is very little work to do in
each time step. Therefore there is a limit to how many CPUs we can scale to,
there just isn't enough work.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is a very old benchmark, and really it should be resized to suit modern
computers (eg increase resolution).&lt;/p&gt;
&lt;h3&gt;x264 Video Encoding x264 is a library that encodes videos into the&lt;/h3&gt;
&lt;p&gt;H.264/MPEG-4 format.&lt;/p&gt;
&lt;p&gt;Mostly vectorisation issues. We have &lt;a href="https://www.bountysource.com/teams/ibm/bounties"&gt;active
bounties&lt;/a&gt; for x264.&lt;/p&gt;
&lt;p&gt;x264 has a lot of integer kernels doing operations on image elements. The math
and vectorisation optimisations are quite complex, so Nick had a quick look at
the basics.  The systems and environments (e.g. gcc version 8.1 for Skylake, 8.0
for POWER9) are not completely apples to apples so for now patterns are more
important than the absolute results. All tests were run with --threads 1 to
avoid SMT effects.&lt;/p&gt;
&lt;p&gt;Skylake is significantly faster than POWER9 on this test: Skylake: 9.20 fps
POWER9 : 3.39 fps&lt;/p&gt;
&lt;p&gt;Let's start with a baseline, run both with --disable-asm that generates
unvectorized binaries from common C code: Skylake: 1.47 fps POWER9 : 1.54 fps&lt;/p&gt;
&lt;p&gt;Even with --disable-asm, the output files are not identical between CPUs or
different compile options, which is a concern with no floating point. Perhaps
there is a bug or some undefined behaviour in the code.&lt;/p&gt;
&lt;p&gt;x264 compiles with -fno-tree-vectorize by default, which disables auto
vectorization. Enabling it (plus LTO) gives: Skylake: 2.25 fps POWER9 : 3.02 fps&lt;/p&gt;
&lt;p&gt;Now let's remove --disable-asm to turn asm optimised code back on. A costly
function, quant_4x4x4 is not vectorized in the POWER9 code.  Without
-fno-tree-vectorize, gcc can vectorize it with a small change to the loop
(output file is unchanged): Skylake: 9.20 fps POWER9 : 3.83 ps&lt;/p&gt;
&lt;p&gt;Restricting Skylake to SSE4.2 with 128 bit vectors (same as POWER9) shows that
AVX2 does't provide huge gains: Skylake: 8.37 fps POWER9 : 3.83 fps&lt;/p&gt;
&lt;p&gt;Skylake is still much faster at the same vector size. It's surprising they are
able to get 5.7x speedup with 128 bit vectors. &lt;/p&gt;
&lt;h3&gt;Primesieve &lt;a href="https://primesieve.org/"&gt;Primesieve&lt;/a&gt; is a program and C/C++&lt;/h3&gt;
&lt;p&gt;library that generates all the prime numbers below a given number. It uses an
optimised &lt;a href="https://upload.wikimedia.org/wikipedia/commons/b/b9/Sieve_of_Eratosthenes_animation.gif"&gt;Sieve of
Eratosthenes&lt;/a&gt;
implementation.&lt;/p&gt;
&lt;p&gt;The algorithm uses the L1 cache size as the sieve size for the core loop.  This
is an issue when we are running in SMT (simulatenous multi-threading) mode (aka
more than one thread per core) as all threads on a core share the same L1 cache
and so will constantly be invalidating each others cache-lines. As you can see
in the table below, running the benchmark in single threaded mode is 30% faster
than in SMT4 mode!&lt;/p&gt;
&lt;p&gt;This means in SMT-4 mode the workload is about 4x too large for the L1 cache.  A
better sieve size to use would be the L1 cache size / number of (online?)
threads per core. Anton posted a &lt;a href="https://github.com/kimwalisch/primesieve/pull/54"&gt;pull
request&lt;/a&gt; to update the sieve
size.&lt;/p&gt;
&lt;p&gt;Interesting that the best overall performance is with the patch applied and in
SMT2 mode.&lt;/p&gt;
&lt;p&gt;Time in seconds:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SMT level&lt;/th&gt;
&lt;th&gt;baseline&lt;/th&gt;
&lt;th&gt;patched&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;14.728&lt;/td&gt;
&lt;td&gt;14.899&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;15.362&lt;/td&gt;
&lt;td&gt;14.040&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;19.489&lt;/td&gt;
&lt;td&gt;17.458&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;FLAC &lt;a href="https://xiph.org/flac/"&gt;FLAC&lt;/a&gt; is an alternative encoding format to&lt;/h3&gt;
&lt;p&gt;MP3. But unlike MP3 encoding it is lossless!  The benchmark here was encoding
audio files into the FLAC format. The key part of this workload is missing
vector support for POWER8 and POWER9. Anton and Amitay submitted this &lt;a href="http://lists.xiph.org/pipermail/flac-dev/2018-July/006351.html"&gt;patch
series&lt;/a&gt; that
adds in POWER specific vector instructions and fixes the configuration options
to correctly detect powerpc versions. With this we get at best a 3.3x
improvement in this benchmark!&lt;/p&gt;
&lt;h3&gt;LAME Despite its name, a recursive acronym for "LAME Ain't an MP3 Encoder",&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://lame.sourceforge.net/"&gt;LAME&lt;/a&gt; is indeed an MP3 encoder.&lt;/p&gt;
&lt;p&gt;Due to configure options &lt;a href="https://sourceforge.net/p/lame/mailman/message/36371506/"&gt;not being parsed
correctly&lt;/a&gt; this
benchmark is built without any optimisation regardless of architecture. We see a
massive speedup by turning optimisations on, and a further 6-8% speedup by
enabling
&lt;a href="https://sourceforge.net/p/lame/mailman/message/36372005/"&gt;USE_FAST_LOG&lt;/a&gt; (which
is already enabled for Intel).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;LAME&lt;/th&gt;
&lt;th&gt;Duration&lt;/th&gt;
&lt;th&gt;Speedup&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Default&lt;/td&gt;
&lt;td&gt;82.1s&lt;/td&gt;
&lt;td&gt;n/a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;With optimisation flags&lt;/td&gt;
&lt;td&gt;16.3s&lt;/td&gt;
&lt;td&gt;~5.0x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;USE_FAST_LOG set&lt;/td&gt;
&lt;td&gt;15.6s&lt;/td&gt;
&lt;td&gt;~5.3x&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For more detail see Joel's
&lt;a href="https://shenki.github.io/LameMP3-on-Power9/"&gt;writeup&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;OpenSSL&lt;/h3&gt;
&lt;p&gt;Mainline OpenSSL is almost 2x faster (than the version phoronix used??) because
of &lt;a href="https://github.com/openssl/openssl/commit/68f6d2a02c8cc30c5c737fc948b7cf023a234b47"&gt;this commit&lt;/a&gt;.
This commit adds some optimised multiplication and squaring assembly code.
Other than that, it's mostly hardware.&lt;/p&gt;
&lt;h3&gt;SciKit-Learn SciKit-Learn is a bunch of python tools for data mining and&lt;/h3&gt;
&lt;p&gt;analysis (aka machine learning).&lt;/p&gt;
&lt;p&gt;Joel noticed that the benchmark spent 92% of the time in libblas. Libblas is a
very basic BLAS (basic linear algebra supprograms) library that python-numpy
uses to do vector and matrix operations.  The default libblas on Ubuntu is only
compiled with -O2. Compiling with -Ofast and using alternative BLAS's that have
PowerPC optimisations (such as libatlas or libopenblas) we see big improvements
in this benchmark (these times are for one run of computations, the benchmark
does this 5 times):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;BLAS used&lt;/th&gt;
&lt;th&gt;Duration&lt;/th&gt;
&lt;th&gt;Speedup&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;libblas -O2&lt;/td&gt;
&lt;td&gt;64.2s&lt;/td&gt;
&lt;td&gt;n/a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;libblas -Ofast&lt;/td&gt;
&lt;td&gt;36.1s&lt;/td&gt;
&lt;td&gt;~1.8x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;libatlas&lt;/td&gt;
&lt;td&gt;8.3s&lt;/td&gt;
&lt;td&gt;~7.7x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;libopenblas&lt;/td&gt;
&lt;td&gt;4.2s&lt;/td&gt;
&lt;td&gt;~15.3x&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;You can read more details about this
&lt;a href="https://shenki.github.io/Scikit-Learn-on-Power9/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Blender Blender is a 3D graphics suite that supports image rendering,&lt;/h3&gt;
&lt;p&gt;animation, simulation and game creation. On the surface it appears that Blender
2.79b (the distro package version that Phoronix used by system/blender-1.0.2)
failed to use more than 15 threads, even when "-t 128" was added to the bender
command line.&lt;/p&gt;
&lt;p&gt;It turns out that even though this benchmark was supposed to be run on CPUs only
(you can choose to render on CPUs or GPUs), the GPU file was always being used.
The GPU file is configured with a very large tile size of 256x256 being used -
which is (fine for
GPUs)[https://docs.blender.org/manual/en/dev/render/cycles/settings/scene/render/performance.html#tiles]
but not great for CPUs. The image size (1280x720) to tile size ratio limits the
number of jobs created and therefore the number threads used. Fortunately this
has already been fixed in the
&lt;a href="https://openbenchmarking.org/test/pts/blender"&gt;pts/blender-1.1.1&lt;/a&gt; of Phoronix.&lt;/p&gt;
&lt;p&gt;To obtain a realistic CPU measurement with more that 15 threads you can force
the use of the cpu file by overwritting the gpu file with the cpu one:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ cp
~/.phoronix-test-suite/installed-tests/system/blender-1.0.2/benchmark/pabellon_barcelona/pavillon_barcelone_cpu.blend
~/.phoronix-test-suite/installed-tests/system/blender-1.0.2/benchmark/pabellon_barcelona/pavillon_barcelone_gpu.blend&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;As you can see in the image below, now all of the cores are being utilised!
&lt;img alt="Blender HTOP Output" src="/images/phoronix/blender-88threads.png" title="Blender with CPU Blend file"&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Benchmark&lt;/th&gt;
&lt;th&gt;Duration (deviation over 3 runs))&lt;/th&gt;
&lt;th&gt;Speedup&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Baseline (GPU blend file)&lt;/td&gt;
&lt;td&gt;1509.97s (0.30%)&lt;/td&gt;
&lt;td&gt;n/a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Single 22-core POWER9 chip (CPU blend file)&lt;/td&gt;
&lt;td&gt;458.64s (0.19%)&lt;/td&gt;
&lt;td&gt;3.29x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Two 22-core POWER9 chips (CPU blend file)&lt;/td&gt;
&lt;td&gt;241.33s (0.25%)&lt;/td&gt;
&lt;td&gt;6.25x&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Pinning the pts/bender-1.0.2, Pabellon Barcelona, CPU-Only test to a single
22-core POWER9 chip (&lt;code&gt;sudo ppc64_cpu --cores-on=22&lt;/code&gt;) and two POWER9 chips
(&lt;code&gt;sudo ppc64_cpu --cores-on=44&lt;/code&gt;) show a huge speedup.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">OzLabs</dc:creator><pubDate>Fri, 27 Jul 2018 00:00:00 +1000</pubDate><guid>tag:sthbrx.github.io,2018-07-27:/blog/2018/07/27/improving-phoronix-benchmarks-date-2018-07-27-2222-authors-rashmica//</guid></item></channel></rss>